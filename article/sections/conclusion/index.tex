\section{Conclusion}\label[section]{conclusion and Future Work}

This work explores parallelism, P- and E-cores and how it affects energy consumption and execution time. We use Windows as the primary OS, but Linux is included as a reference point. After conducting the initial experiments, we apply Cochran's formula to determine a sample size given the desired confidence level and margin of error. We find that the sample size determined by Cochran's formula is in many cases larger than what is currently seen in the research, and also in some cases larger than we can reasonably collect. While Windows provides valuable depth to the analysis of energy consumption, Linux is overall the more convenient choice due to its minimalist nature with less pre-installed software and background processes. We find that reaching definitive conclusions is challenging as the results are very hardware and compiler dependent, and similar observations are not guaranteed between OSes.

%% RQ1: c++ compler
Since RAPL is not available on Windows, we compare alternatives by measuring energy consumption on C++ microbenchmarks, compiled on the most energy efficient compiler of the ones we test. The most energy efficient C++ compiler is identified through the first experiment, where we find that there is a significant difference in performance between compilers. The most energy efficient compiler is found be Intel's oneAPI, due to its utilization of AVX, for parallelism, and other optimizations, such a loop unrolling.

%because of its use of parallelism and \texttt{ymm} registers, only found on Intel CPUs.

%% RQ2: measuring instruments
We test different measuring instruments and decide which to use on Windows by comparing microbenchmarks compiled on oneAPI. A similar correlation of $0.68 - 0.70$ and $0.67 - 0.71$ (UPDATE WITH NEW CORRELATION NUmbers AND MENTION PLUG) is found for the software-based measuring instruments with our ground truth (Clamp) on DUT2. We suspect that the similarity is due to all the software-based measuring instruments utilizing the same registers when reporting the energy consumption. We choose Intel Power Gadget as our preferred software-based measuring instrument, because of its usability compared to other measuring instruments. In a future work, it could be interesting to extend this analysis to include factors such as the overhead of the measuring instruments for Windows, to see how they compare to RAPL.

%% RQ4: Effect of P- and E- cores
In the third experiment, we analyze the performance of P- and E-cores, which shows a lower execution time and total dynamic energy consumption for P-cores, but a higher dynamic energy consumption per second compared to E-cores. This indicates that for most benchmarks, the P-cores are preferred. However, the intended workload for E-cores is small, non-time-critical jobs, which is our microbenchmarks do not simulate. In future work, the P- and E-cores setup could be tested with more focus on workloads intended for E-cores.

%% RQ3: the effect parallelism has on energy consumption
In the third experiment, we explore parallelism and its effect on energy consumption using two macrobenchmarks, PCMark 10 and 3DMark. One represents a realistic use case, including tasks such as video conferencing, web browsing, and video editing, while the other simulates a more demanding workload. Both macrobenchmarks are executed on different numbers of cores to examine the effects of additional cores. For both macrobenchmarks, we find a relationship between the total dynamic energy consumption, execution time, and dynamic energy consumption per second. As more cores are allocated, the execution time and total dynamic energy consumption decrease, while the dynamic energy consumption per second increases. However, the relationship is non-linear, with the execution time decreasing more than the dynamic energy consumption, illustrating diminishing returns. This diminishing return means that at a certain number of cores, additional cores have no notable effect on the execution time or the total dynamic energy consumption, and this number of cores will be higher for more demanding workloads.


