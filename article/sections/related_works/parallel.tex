\subsection{Parallel Software}

Amdahl's law describes the maximum potential speedup that can be achieved through the parallelization of an algorithm based on the proportion of the algorithm that can be parallelized and the number of cores used.\cite{amdahl1967validity} In \cite{woo2008extending} Amdahl's law, was extended to also estimate the energy consumption.  Then three different many-core designs were compared with different amounts of cores using the extended Amdahl's law. The comparison showed that a CPU can lose its energy efficiency as the number of cores rises and it was argued that knowing how parallelizable a program is before execution allows for calculating the optimal number of active cores for maximizing performance and energy consumption. However, the comparison was based on an analytical model and not real measurements.\cite{woo2008extending}

\cite{prinslow2011overview} presented a program that solves Laplace equations and compares the observed speedup for computing the Laplace equations with one, two, and four cores, with estimates given by Amdahl's law and Gustafson's law.  Gustafson's law evaluates the speedup of a parallel program based on the size of the problem and the number of cores. Unlike Amdahl's law which assumes a fixed problem size and a fixed proportion of the program that can be parallelized, Gustafson's law takes into account that larger problems can be solved when more cores are available and that the parallelization of a program can scale with the problem size. Comparing the observed speedup and the estimates it was clear that Gustafson's law is more optimistic than Amdahl's law, however, both estimate smaller speedups than the observed speedup on two and four cores. \cite{prinslow2011overview}

% RAPL, C++, 30 runs
%, explicit thread creation, fixed-size thread pooling, and work stealing, from Java, are analyzed regarding energy consumption. Furthermore, the three aspects: the number of threads, task division strategy, and characteristics of the data.\cite{Pinto2014}

In \cite{Pinto2014}, three different thread management constructs from Java were explored and analyzed regarding energy consumption. It was found that as the number of threads increased, energy consumption would do the same. However, this was only up to a certain point, after which energy consumption would start to decrease as the number of threads approached the number of cores in the CPU. The peak of this energy consumption was application-dependent. The study also found that in eight out of nine benchmarks, there was a decrease in execution time when transitioning from sequential execution on one thread to using multiple threads. It should be noted, though, that four of their benchmarks were embarrassingly parallel, while only one was embarrassingly serial. Moreover, decreased execution time does not necessarily imply decreased energy consumption, because in six out of nine benchmarks, the lowest energy consumption was found in the sequential version using one thread. Furthermore, the study investigated the energy-performance trade-off using the Energy-Delay-Product (EDP), which is the product of energy consumption and execution time. Using EDP, the study generally found parallel execution to be more favorable; however, depending on the benchmark, increasing the number of threads might not result in an improvement in EDP.\cite{Pinto2014}
% This website says that EDP is not adequate https://greensoftware.foundation/articles/gps-up-a-better-metric-for-comparing-software-energy-efficiency

In \cite{abdelhafez2019}, the energy consumption for sequential and parallel genetic algorithms was explored, where one research question aimed to explore the impact on energy consumption when using different numbers of cores. It found that a larger number of cores in the execution pool results in a lower running time and energy consumption, and conclude that parallelism can help reduce energy consumption. Parallelism's ability to reduce energy consumption was argued to be due to the large number of cores working to solve the problem simultaneously, where the combination of more cores, and more parallel operations per time unit will require less energy. When considering parallel software, it also found asynchronous implementations to use less energy, because there are no idle cores waiting for data in asynchronous implementations, while in synchronous implementations cores can be blocked during runtime, while waiting for responses from other cores.

In \cite{Lindholt2022}, the behavior of parallel applications and the relationship between execution time and energy consumption are explored. It tests four different language constructs which can be used to implement parallelism in C\#. Furthermore, it uses varying amounts of threads and a sample of micro- and macro-benchmarks. It found that workload size has a large influence on running time and energy efficiency and that a certain limit must be reached before improvements can be observed when changing a sequential program into a parallel one. Additionally, it was found that execution time and energy consumption of parallel benchmarks do not always correlate. Comparing micro- and macro-benchmarks the findings remain consistent, although the impact becomes low for the macrobenchmarks due to an overall larger energy consumption. Furthermore, it has included some recommendations, which should be considered:\cite{Lindholt2022}

\begin{itemize}
    \item Shield cores: Avoid unintended threads running on the cores used in the benchmarking
    \item PowerUp: Can be used to ensure that benchmark is not optimized away during compilation
    \item Static clock: Make the clock rate of the CPU as static as possible
    \item Interrupt request: Avoid interrupt requests being sent to cores used in the benchmarking 
    \item Turn off CPU turbo boost
    \item Turn off hyperthreading
\end{itemize}