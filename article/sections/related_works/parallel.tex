\subsection{Parallel Software}

Amdahl's law describes the maximum potential speedup that can be achieved through the parallelization of an algorithm based on the proportion of the algorithm that can be parallelized and the number of cores used.\cite{amdahl1967validity} In \cite{woo2008extending} Amdahl's law, was extended to also estimate the energy consumption.  Then three different many-core designs were compared with different amounts of cores using the extended Amdahl's law. The comparison showed that a CPU can lose its energy efficiency as the number of cores increases and it was argued that knowing how parallelizable a program is before execution allows for calculating the optimal number of active cores for maximizing performance and energy consumption. However, the comparison was based on an analytical model and not real measurements.\cite{woo2008extending}

\cite{prinslow2011overview} compares the observed speedup of computing Laplace equations with one, two, and four cores, with estimates given by Amdahl's law and Gustafson's law.  Gustafson's law evaluates the speedup of a parallel program based on the size of the problem and the number of cores. Unlike Amdahl's law which assumes a fixed problem size and a fixed proportion of the program that can be parallelized, Gustafson's law takes into account that larger problems can be solved when more cores are available and that the parallelization of a program can scale with the problem size. Comparing the observed speedup and the estimates it was clear that Gustafson's law is more optimistic than Amdahl's law, however, both estimate smaller speedups than the observed speedup on two and four cores. \cite{prinslow2011overview}

% RAPL, C++, 30 runs
%, explicit thread creation, fixed-size thread pooling, and work stealing, from Java, are analyzed regarding energy consumption. Furthermore, the three aspects: the number of threads, task division strategy, and characteristics of the data.\cite{Pinto2014}

In \cite{Pinto2014}, three different thread management constructs from Java were explored and analyzed. It was found that the energy consumption increased with the number of threads used. However, after a certain point energy consumption would start to decrease as the number of threads approached the number of cores in the CPU. The peak of the energy consumption was application-dependent. The study also found that in eight out of nine benchmarks, there was a decrease in execution time when transitioning from sequential execution on one thread to using multiple threads. It should be noted, though, that four of their benchmarks were embarrassingly parallel, while only one was embarrassingly serial. Moreover, decreased execution time does not necessarily imply decreased energy consumption, because in six out of nine benchmarks, the lowest energy consumption was found in the sequential version. Furthermore, the study used Energy-Delay-Product (EDP), the product of energy consumption and execution time and found that in general parallel execution was favorable. However,increasing the number of threads was not an improvement for all of the benchmarks.\cite{Pinto2014}
% This website says that EDP is not adequate https://greensoftware.foundation/articles/gps-up-a-better-metric-for-comparing-software-energy-efficiency

In \cite{abdelhafez2019}, found that a larger number of cores in the execution pool results in a lower running time and energy consumption, and conclude that parallelism can help reduce energy consumption for genetic algorithms. %Parallelism's ability to reduce energy consumption was argued to be due to the large number of cores working to solve the problem simultaneously, where the combination of more cores, and more parallel operations per time unit will require less energy. 
When considering parallel software, it also found asynchronous implementations to use less energy, because there are no idle cores waiting for data in asynchronous implementations, while in synchronous implementations cores can be blocked during runtime, while waiting for responses from other cores.

In \cite{Lindholt2022}, %the behavior of parallel applications and the relationship between execution time and energy consumption are explored. It tests 
four different language constructs which can be used to implement parallelism in C\# are tested. Furthermore, they uses varying amounts of threads and a sample of micro- and macro-benchmarks. They found that workload size has a large influence on run time and energy efficiency and that a certain limit must be reached before improvements can be observed when changing a sequential program into a parallel one. Additionally, it was found that execution time and energy consumption of parallel benchmarks do not always correlate. Comparing micro- and macro-benchmarks the findings remain consistent, although the impact becomes low for the macrobenchmarks due to an overall larger energy consumption. Furthermore, it has included some recommendations, which are considered in our setup:\cite{Lindholt2022}

\begin{itemize}
    %\item Shield cores: Avoid unintended threads running on the cores used in the benchmarking
    %\item PowerUp: Can be used to ensure that benchmark is not optimized away during compilation
    \item Static clock: Make the clock rate of the CPU as static as possible
    %\item Interrupt request: Avoid interrupt requests being sent to cores used in the benchmarking 
    \item Turn off CPU turbo boost
    \item Turn off hyperthreading
\end{itemize}