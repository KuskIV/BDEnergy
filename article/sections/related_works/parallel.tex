\subsection{Parallel Software}

Amdahl's law describes the maximum potential speedup that can be achieved through the parallelization of an algorithm based on the proportion of the algorithm that can be parallelized and the number of cores used.\cite{amdahl1967validity} In \cite{woo2008extending} Amdahl's law, is extended to also estimate the energy consumption.  Then three different many-core designs are compared with different amounts of cores using the extended Amdahl's law. It shows that a CPU can lose its energy efficiency as the number of cores rises and it is argued that knowing how parallelizable a program is before execution allows for calculating the optimal number of active cores for maximizing performance and energy consumption. It is however based on an analytical model and not real-life measurements.\cite{woo2008extending}

The paper \cite{prinslow2011overview} presents a program that solves Laplace equations and compares the observed speed up for computing the Laplace equations with one, two, and four cores, with estimates given by Amdahl's law and Gustafson's law.  Gustafson's law evaluates the speedup of a parallel program based on the size of the problem and the number of cores. Unlike Amdahl's law which assumes a fixed problem size and a fixed proportion of the program that can be parallelized, Gustafson's law takes into account that larger problems can be solved when more cores are available and that the parallelization of a program can scale with the problem size. Comparing the observed speed-up and the estimates it is adamant that Gustafson's law is more optimistic than Amdahl's law, however, both estimate smaller speed-ups than the observed speed-up on two and four cores. \cite{prinslow2011overview}

% RAPL, C++, 30 runs
%, explicit thread creation, fixed-size thread pooling, and work stealing, from Java, are analyzed regarding energy consumption. Furthermore, the three aspects: the number of threads, task division strategy, and characteristics of the data.\cite{Pinto2014}

In \cite{Pinto2014}, three different thread management constructs from Java are explored and analyzed regarding energy consumption. It found that as the number of threads increased, the energy consumption would do the same. This was however only to a certain point, where from this point the energy consumption would start to decrease as the number of threads started to approach the number of cores in the CPU. However, the peak of this energy consumption was application dependent.It also found that in eight out of nine benchmarks, there was a decrease in execution time going from sequential execution on one thread to using multiple threads. However, it should be noted that four of their benchmarks are embarrassingly parallel whereas only one was embarrassingly serial. It should also be noted that decreased execution time does not necessarily mean a decreased energy consumption, because in six out of nine benchmarks the lowest energy consumption was found in the sequential version using one thread. Furthermore, it investigated the energy-performance trade-off using the Energy-Delay-Product (EDP), which was the product between energy consumption and execution time. Using EDP it generally found parallel execution to be more favorable however depending on the benchmark increasing the number of threads may not be aligned with an improvement of EDP.\cite{Pinto2014}
% This website says that EDP is not adequate https://greensoftware.foundation/articles/gps-up-a-better-metric-for-comparing-software-energy-efficiency

In \cite{abdelhafez2019}, the energy consumption for sequential and parallel genetic algorithms was explored, where one research question aims to explore the impact on energy consumption when using different numbers of cores. It found that a larger number of cores in the execution pool results in a lower running time and energy consumption, and conclude that parallelism can help reduce energy consumption. Parallelism's ability to reduce energy consumption was argued to be due to the large number of cores working to solve the problem simultaneously, where the combination of more cores, and more parallel operations per time unit will require less energy. When considering parallel software, it also found asynchronous implementations to use less energy, because there are no idle cores waiting for data in asynchronous implementations, while in synchronous implementations cores can be blocked during runtime, while waiting for responses from other cores. 


In \cite{Lindholt2022}, the behavior of parallel applications and the relationship between execution time and energy consumption are explored. It tests four different language constructs which can be used to implement parallelism in C\#. Furthermore, it uses varying amounts of threads and a sample of micro- and macro-benchmarks. It found that workload size has a large influence on running time and energy efficiency and that a certain limit must be reached before improvements can be observed when changing a sequential program into a parallel one. Additionally, it was found that execution time and energy consumption of parallel benchmarks do not always correlate. Comparing micro- and macro-benchmarks the findings remain consistent, although the impact becomes low for the macrobenchmarks due to an overall larger energy consumption. Furthermore, it has included some recommendations, which should be considered:\cite{Lindholt2022}

\begin{itemize}
    \item Shield cores: Avoid unintended threads running on the cores used in the benchmarking
    \item PowerUp: Can be used to ensure that benchmark is not optimized away during compilation
    \item Static clock: Make the clock rate of the CPU as static as possible
    \item Interrupt request: Avoid interrupt requests being sent to cores used in the benchmarking 
    \item Turn off CPU turbo boost
    \item Turn off hyperthreading
\end{itemize}