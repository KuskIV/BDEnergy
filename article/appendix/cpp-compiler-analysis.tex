\section{C++ Compiler Analysis}\label{app:compiler-analysis}

In the first experiment in \cref{subsec:exp_one}, different compilers were compared. This experiment found that both the energy consumption and measurements required deviated between compilers. The largest difference was found when comparing the oneAPI against other compilers which could be a result of dead code elimination by the compiler, which could remove the benchmark we aimed to test\cite{sestoft2013microbenchmarks}. The analysis to ensure the benchmark had not been optimized away, was conducted by comparing the oneAPI against MinGW, by decompiling the executables and comparing the instructions.

% The executable from oneAPI (668 mb) was three times as large as for MinGW (220 mb), so this indicates that the code has not been removed, but further analysis is required to confirm this

When comparing the Assembly code structure between the main functions from the compilers, the oneAPI used several function calls unique for intel process such as \texttt{\_\_\_intel\_new\_feature\_proc\_init} and \texttt{\_\_intel\_fast\_memset}, where both functions were part of Intel's default C++ libraries\cite{Intelassembly}. The MinGW used general purpose registers more and utilizes C++ Standard Library, in the assembly more than oneAPI.

\input{appendix/assemblyListing}

% The minGw compiled code seem to make more use of purpose made registers and operations in the setup, such as movaps and xmm regs for floating point operations, where intel seems to have a preference for general purpose registers. 
% In terms of of libraries used it seems to utilities std much more.
%  The mvsc instead makes more use of general functions that are part of C runtime on windows\cite{SCRTassembly}, it also utilizes locks, system calls more frequently seemingly for thread synchronization. Another thing seemingly more common in the microsoft c++ compiled assembly is error handling. 

% https://www.intel.com/content/www/us/en/developer/tools/isa-extensions/overview.html


When looking at the Mandelbrot function, MinGW only used standard X86 instruction\cite{X86} to perform the calculations on the floating points and \texttt{xmm} registers to store the values. Opposed to this, oneAPI's implementation also utilized Advance Vector extensions (AVX)\cite{AVXIntel}, to perform the calculations, and frequently utilizing \texttt{ymm} registers instead of \texttt{xmm}. The usage of AVX resulted in a increase in calculation speed as it allowed for multiple calculations to be performed in parallel. The AVX technology was a set of instructions introduced by Intel to enhance the performance of floating-point-intensive applications\cite{AVXIntel}. Compared to MinGW, oneAPI is better at optimizing the code for the AVX architecture and take full advantage of the processing power of the CPU. This usage of AVX was illustrated in \cref{fig:assembly1} and \cref{fig:assembly2}, where the differences between MinGW and oneAPIs way of handling the setup for the Mandelbrot function was shown. The listings show the two different approaches used to load values into local variables used by oneAPI and MinGW. When the two approaches were compared, oneAPI used vectorized instructions such as \texttt{vmovsd}, from AVX, while MinGW used simple instructions such as \texttt{movsd}. The Vectorized instructions will be better for execution time, as this operation could be performed on multiple values simultaneously in parallel.

oneAPIs use of parallel operations, for example with AVX, and smaller optimizations such a loop unrolling was most likely the reason why it was able to achieve a lower execution time. The energy consumption was however close to the energy consumption by the other compilers, which is an observation also found by other studies about energy consumption and parallelism\cite{Lindholt2022}. %The inclusion of extension libraries could be the reasons why the executable made by oneAPI is roughly 3 times larger but with a lower runtime than MinGW and the the other compilers.




% To conclude we were able to confirm that the test case compiled by the intel c++ compiler did not remove any of the relevant executions from the executable, and performed the correct calculations. The speed up seems mainly be caused be the usage of AVX in parallel, and smaller optimizations such a loop unrolling.

% Additional note:
% intel also seems to create significantly bigger files. 3x larger
% intel uses both xmm and ymm depending on need. AVX instructions
% "Overall, YMM registers are a significant improvement over XMM registers in enabling data parallelism and speeding up certain types of computational tasks, especially those that involve large amounts of data."


% in Mingw the Mandelbrot function seems to be a subroutine. ming also seems to only use xmm registers and general purpose

% Mingw: movaps, moveapd, movsd, subsd, divsd, mulsd, cvtsi2sd,comisd,setae, nop, retn

% intel: vmovsd,vsubsd,vmovss,vmovaps,test,vmovapd,vorpd,vdivsd,vmulsd,vbroadcastsd, vmovlpd, vpaddd,vextracti128,vpmovzxdq,vpor,vfmadd213pd,vmovupd,vzeroupper,vfmsub231sd,vaddsd,vperm2f128,vshufpd,vfmsub213sd,vfmsub231sd,vpermilpd,setbe,movzx,vucomisd,vmulpd,dec